%! TEX root = ../acmpaper/paper.tex
\section{Example Use-Cases}
\label{ssec:use_cases}
For the scope of this paper, we have developed two exemplary use-cases for our framework that demonstrates our layered verification approach. In the first use-case, we defined a simple program that uses multiple different, partly independent type systems. For our second example, we use our framework to present a more flexible approach to using Liquid Types.

\subsection{Use Case 1 -- File Processing}
\label{sssec:use_case_1}

In our first use case we implemented a small program that processes the contents of a text file. Througout this section we will describe the program and the implemented layers required to realize this program. Lastly we will discuss the findings and benefits we gained from using our layered verification approach.

\subsubsection{Description}
In our first use-case we design a small program that reads contents from a file and performs certain operations based on that. The base code for our example can be found in Listing \ref{lst:uc1_code}. In our example, the file to be read will contain one number per each line. Depending on whether the number is positive or negative, we add the number as is or the square of the number to the resulting value.

\begin{lstlisting}
processLine lines idx length {
    end := idx == length

    if end then {
        0
    } else {

        curLine := getLine(lines, idx)

        number := strToInt(curLine)

        greaterThanZero := number > 0

        if greaterThanZero then {
            number + processLine(lines, idx + 1, length)
        } else {
            (number * number) + processLine(lines, idx + 1, length)
        }

    }
}

processLines lines {
    length := len(lines)

    idx := 0
    processLine(lines, idx, length)
}

fileName := "numbers.data"
fileHandle := openFile(fileName)
lines := readLines(fileHandle)
closeFile(fileHandle)
total := processLines(lines)

print(total)
total

\end{lstlisting}

All functions that have not been defined directly \ref{lst:uc1_code} are provided in a separate, external python file. As our language on itself does not include a type system and there are no layer annotations in the code above, no type checking will be performed on the code as it is presented.

However even this simple example could already introduce several errors that could be prevented by introducing some static analysis. First of all, it does not provide any information about the variable and function type and thus, we cannot ensure that functions are called with arguments of the correct types which might lead to runtime errors.

Additionally we our code interacts with the file it operates on through a file descriptor. TThis file descriptor can be viewed as a resource that might have an implicit or explicit internal state. In a very simple approach this file descriptor could be in the states "Open" or "Closed". In order to read from it, it should be in an "Open" state and additionally we should ensure that by the end of our program the resource has been properly closed again.

In order to improve our example code and allow static analysis, we therefore will introduce three layers:
\begin{enumerate}
	\item A \textit{Type} Layer -- This layer will be used to simply define variable and function types
	\item The \textit{Typechecking} Layer -- This layer will allow to flexibly define a type system and then use the information provided by the \textit{Type} layer to check if the program is well-typed. It therefore depends on the \textit{Type} layer to provide the type information.
	\item A \textit{State} Layer -- This layer will be used to define states on variables. Additionally it can model state transitions. We will use it to track the state of the file descriptor. This layer operates completely independent from the \textit{Type} and \textit{Typechecking} layer.
\end{enumerate}

\subsubsection{Implemented Layers}
In the following sections we will explain in more detail how the layers are implemented and what Syntax they use.

\paragraph{Types Layer}
The \textit{Types} layer is the first layer that is checked. It is used to define the types of variables and functions. To define the type of a variable we use the \texttt{Layer} syntax of our language. A layer definition for the \textit{Types} layer looks as follows:

\begin{lstlisting}
identifier :: types :: Type
\end{lstlisting}

The \texttt{identifier} is the name of the variable or function for which we want to define the type. The \texttt{types} keyword is used to associate this information with the correct layer. The \texttt{Type} is the desired type information to be annotated. There are no restrictions on how a \texttt{Type} should look, as the types layer simply annotates the given string into the current node and does not further process it. For example to define the type of a variable \texttt{foo} as \texttt{int} we would write:

\begin{lstlisting}
foo :: types :: int
\end{lstlisting}

In order to define the type of a function, there is a slight adaption to this syntax. While the first two parts are identical to the variable definition, we now need to provide type information for each argument of the function. This is done by using the \texttt{Type} syntax for each argument and then separating them with an arrow symbol \texttt{->}. The return type of the function is then defined by the last \texttt{Type}. If a function does not take an argument the defintion simply starts with the arrow symbol. The following code piece contains an example for a function \texttt{f} that takes two arguments of type \texttt{int} and returns a value of type \texttt{bool}, and a function \texttt{g} that does not take any arguments and returns a value of type \texttt{string}:

\begin{lstlisting}
f :: types :: int -> int -> bool
g :: types :: -> string
\end{lstlisting}

It is important to note that the \textit{Types} layer does not perform any type checking. It simply annotates the given type information into the AST. The \textit{Types} layer only checks for the following inconsistencies:

\begin{itemize}
	\item The type for a variable can only be defined once in the current scope.
	\item When encountering a function definition, the type for it needs to be defined before the function signature. Additionally the number of arguments in the function signature needs to match the number of arguments in the type definition.
\end{itemize}

Any further type checking is performed by the \textit{Typechecking} layer.

\paragraph{Typechecking Layer}

The \textit{Typechecking} layer is used to define a type system and then use the information provided by the \textit{Types} layer to check if the program is well-typed. It therefore depends on the \textit{Types} layer to provide the type information. In our implementation of the type checker, we do not impose any restrictions on the specific type system. We rather provide a generic type checking implementation that allows the user to flexibly define their own types and subtype relationships. However, since our language implicitly natively requires specific expressions to be of a number or boolean type, there are implicitly part of our type system.

To define the specific type system, we use the \texttt{Layer} syntax of our language. However, instead of defining layers for identifiers as in the \textit{Types} layer, we reserve a selected set of keywords to define the type system. Depending on the definition provided by the user, the type checker will internally build a type graph that is used to perform the type checking.

The following keywords are reserved and can be used to define parts of the type system:

\begin{itemize}
	\item \texttt{logicalTypes} -- This keyword is used to define a set of logical types. Multiple types can be defined by separating them with a space.
	\item \texttt{numTypes} -- This keyword is used to define a set of numeric types. Multiple types can be defined by separating them with a space.
	\item \texttt{subtype} -- This keyword is used to define a subtype relationship between two or more types. The syntax for a subtype relationship is \texttt{<type1> <: <type2> <: ... <: <typeN>}. The subtype relationship is then defined by the order of the types. The first type is the supertype and the following type is a subtype of the previous type.
\end{itemize}

The following code piece is a short demonstration of a type system containing different logical types, numeric types and subtype relationships:

\begin{lstlisting}
logicalTypes :: typecheck :: bool
numTypes :: typecheck :: int float
subtype :: typecheck :: float <: int
\end{lstlisting}

The type system defined by the user will be used to perform the typechecking. To perform this typecheck the type checker accesses the annotations provided by the \textit{Types} layer. For the case that a type is neither a numeric or logical type and it does not have any subtype relationships, it is not required to explicitly define it in the type system. The type checker will then simply assume the existance of such a type that is not a subtype of any other type nor does it have any subtypes.

Our type checker will perform the following checks:

\begin{itemize}
	\item The type of each variable needs to be defined.
	\item When assigning a value to a variable, the type of the value needs to be a subtype of the type of the variable.
	\item When performing a logical operations (e.g. \texttt{\&\&}, \texttt{||}) the type of the operands needs to be a logical type. The result of the operation will be a logical type.
	\item When performing a numeric operation (e.g. \texttt{+}, \texttt{-}, \texttt{*}, \texttt{/}) the type of the operands needs to be a numeric type. The result of the operation will be the most general numeric type of the operands.
	\item When performing a comparison operation (e.g. \texttt{==}, \texttt{!=}, \texttt{<}, \texttt{>}, \texttt{<=}, \texttt{>=}) the type of the operands needs to be compatible. This means that either the right hand side is a subtype of the left hand side or the left hand side is a subtype of the right hand side. The result of such an operation is always a boolean value.
	\item In an \texttt{if} statement the condition needs to be a logical type.
	\item When performing a function call, the number of arguments needs to match the number of arguments in the function definition. Additionally the type of each argument needs to be a subtype of the type of the corresponding argument in the function definition.
\end{itemize}

Since we require the type of each variable to be defined, this means we require full information about the types of all variables. We do not perform any type inference. This is a deliberate design decision, as we want to keep the language as simple as possible. However, by the design of our language, it would be possible to develop an additional layer that runs after the \textit{Types} layer but before the \textit{Typechecking} layer that performs a type inference based on the incomplete information provided.

\paragraph{State Layer}

The \textit{State} layer is used to define states on variables. Similarly, we can use it to check if a variable has a certain state and define state transitions. This can for example be used to track the state of resources that are used by a program. In our implementation, the state of a variable is completely independent of its type, therefore it does not require any dependencies on the \textit{Types} layer.

The state of a variable is defined by a set of strings. Generally there are two ways to check the state of a variable or transition it's state to a new one. Firstly, we can explicitly do this by using a layer statement of the language. Secondly, we can also impose state requirements on arguments of function calls. Then when passing a variable to a function, the layer will check if the variable has the required state and apply the state transition if there are any.

Similar to the \textit{Types} layer, the \textit{State} layer uses the \texttt{Layer} syntax of the language to define the state of a variable. The first part of the layer statement defines the variable or function name to define a state on, while the second part is simply the layer identifier \texttt{state}. The last part of the layer definition defines the state.

A state definition is enclosed by curly brackets and can contain the following parts:

\begin{itemize}
	\item A state \textit{requirement} -- Imposes a restrition on the current state the variable needs to have. This is simply a string that needs to be part of the current state of the variable.
	\item A state \textit{transition} -- Defines a transition to a new state. Generally a state transition has the form \texttt{<oldState> => <newState>}. However, either the old or new state may be omitted. When omitting the old state, this simply means that something is added to the current state of the variable unconditionally. When omitting the new state, this means that the corresponding state string will be removed from the set of states.
\end{itemize}

For our use-case, we want to track the state of the file descriptor. Specifically, we want to make sure, that the file handle is open before we can read from it. Additionally, we do not want to read from a file handle again once it has already been read. Therefore, we define the states \texttt{Open}, \texttt{Consumed} and \texttt{Closed} and define the appropriate state transistions as seen in Listing \ref{lst:uc1_state}. Additionally, at the end of the program, we want to make sure that the file handle is closed. Therefore, we define a state requirement that the file handle needs to be in the state \texttt{Closed}.

\begin{lstlisting}
createFD :: state :: {} -> { Closed }
openFile :: state :: {Closed => Open} -> {}
readLines :: state :: {Open => Consumed} -> {}
closeFile :: state :: {Consumed => Closed} -> {}

-- State requirement at the end of the program
fileDescriptor :: state :: {Closed}
\end{lstlisting}

The final program with all layer annotations can be found in Listing \ref{lst:uc1_annotated}. With these three layers, we have defined the complete type system for this use-case. Using these three layers we can now ensure the following properties of our program statically:

\begin{itemize}
	\item Our program is type safe. This means that we can be sure that the program will not crash due to type errors.
	\item Using the state layer, we ensure that the file descriptor is handled correctly and is in a closed state at the end of the program.
\end{itemize}

\begin{lstlisting}
-- Type Layer Definitions for externally defined functions
getLine :: types :: [string] -> int -> string
strToInt :: types :: string -> int
len :: types :: [string] -> int
createFD :: types :: string -> FileHandle
openFile :: types :: FileHandle -> void
readLines :: types :: FileHandle -> [string]
closeFile :: types :: FileHandle -> void
print :: types :: Any -> void

-- Layer definitions for type checking
logicalTypes :: typecheck :: bool
numTypes :: typecheck :: int
subtype :: typecheck :: int <: Any
subtype :: typecheck :: string <: Any

-- State layer definitions
createFD :: state :: {} -> { Closed }
openFile :: state :: {Closed => Open} -> {}
readLines :: state :: {Open => Consumed} -> {}
closeFile :: state :: {Consumed => Closed} -> {}

processLine :: types :: [string] -> int -> int -> int
processLine lines idx length {

    end :: types :: bool
    end := idx == length

    if end then {
        0
    } else {

        curLine :: types :: string
        curLine := getLine(lines, idx)

        number :: types :: int
        number := strToInt(curLine)

        greaterThanZero :: types :: bool
        greaterThanZero := number > 0

        if greaterThanZero then {
            number + processLine(lines, idx + 1, length)
        } else {
            (number * number) + processLine(lines, idx + 1, length)
        }

    }
}

processLines :: types :: [string] -> int
processLines lines {
    length :: types :: int
    length := len(lines)

    idx :: types :: int
    idx := 0
    processLine(lines, idx, length)
}

fileName :: types :: string
fileName := "numbers.data"

fileDescriptor :: types :: FileHandle
fileDescriptor := createFD(fileName)

openFile(fileDescriptor)

lines :: types :: [string]
lines := readLines(fileDescriptor)

closeFile(fileDescriptor)

total :: types :: int
total := processLines(lines)

print(total)
total

-- State post-conditions
-- The file handle is closed after the program has finished
fileDescriptor :: state :: {Closed}
\end{lstlisting}

\subsubsection{Discussion}

Implementing this first use-case has given us valuable results and insights on our approach. We have successfully implemented three layers independently from each other, however since the \textit{Typecheck} layer depends on the information provided by the \textit{Types} layer, we successfully demonstrated, that information can be communicated between layers. We have also successfully demonstrated that the layers can be used to define a type system for a program. This means that we can use the layers to define a type system for a program and then use the type checker to check if the program is type safe.

Furthermore, as a result of this use-case, we provide an implementation of a state layer. This layer can be used to define states on variables and functions and to check if a variable has a certain state. Additionally, we can use the state layer to define state transitions. This can be used to track the state of resources that are used by a program. We believe that this layer is suitable for a wide range of applications far beyond the simple demonstration we have shown in this use-case.

One shortcoming of our implementation is that we require that the \textit{Types} layer needs to provide full information on the types of all variables and functions. For a developer it would be much more flexible if it would be possible to only provide partial information and use type-inference to deduce the missing information. However, by the design of our framework extending the example to also support type inference is possible. We could for example add a new layer that runs after the \textit{Types} layer but before the \textit{Typecheck} layer. This layer could then perform type inference and annotate the missing information to the AST. This way the \textit{Typecheck} layer would have all the information it needs to perform the type checking. However for the scope of this paper, we have decided not to implement this feature.

\subsection{Use Case 2 -- Liquid Types}
\label{sssec:use_case_2}

In our second use-case we use a scenario where we verify different properties of a program based on liquid types. Specifically, we show how our approach can be used to improve the verification of orthogonal properties.

\subsubsection{Description}
\label{sssec:uc2_description}

Liquid Types can be particulary useful when operating with machine learning pipelines: Learning datasets usually contain many dimensions that can often be manipulated independently from one another. In its' simplest form, a dataset can be compared to a two-dimensional table where we can add and remove rows or columns independently from one another. However some operations may require interaction of these two dimensions. For example, in our two dimensional running example we could consider each column a specific feature and each row a specific datapoint. If we now want to train a model based on a specific dataset, we might want to ensure that we have enough datapoints in relation to the number of features we observe.

For our example use-case we model some basic operations that might be used in a machine learning environment to create and modify datasets. Specifically, we will support the following operations:
\begin{itemize}
	\item \texttt{createDataset(c,r)} -- Creates a dataset with a specific number of rows and columns
	\item \texttt{add\_rows(d,n)} -- Adds a specific number of rows to a dataset
	\item \texttt{add\_cols(d,n)} -- Adds a specific number of columns to a dataset
	\item \texttt{reduce\_cols(d,n)} -- Reduces a datset to a specific number of columns
	\item \texttt{sample(d,n)} -- Samples a specific number of datapoints from a dataset
	\item \texttt{train(d)} -- Trains a model based on a specified dataset
\end{itemize}

From the operations above, it is already clear that these operations will affect rows and columns of a dataset. Sometimes independently from one another, but some operations will also require or provide information about both of them. We will describe these changes in dimensions using liquid types. Under the assumption that the in-built function \texttt{n\_rows(d)} and \texttt{n\_cols(d)} return the number of rows and columns of a dataset respectively, these function have the following liquid signatures:

\begin{lstlisting}[numbers=none,tabsize=8,caption={Liquid Signatures of functions in Use-Case 2},label={lst:uc2_liq_sig}]
createDataset :: { c:Int | (c >= 0) }
	-> { r:Int | (r >= 0) }
	-> { d:DataSet | (n_cols(d) == c) && (n_rows(d) == r) }

add_rows :: { d:DataSet | n_cols(d) > 0 }
	-> {n:Int | n>0} 
	-> { d2:DataSet | (n_rows(d2) == (n_rows(d) + n)) && (n_cols(d2) == n_cols(d)) }

add_cols :: { d:DataSet | true } 
	-> { n:Int | n>0 }
	-> { d2:DataSet | (n_cols(d2) == (n_cols(d) + n)) && (n_rows(d2) == n_rows(d)) }

reduce_cols :: { d:DataSet | true } 
	-> { c:Int | (c >= 0) && (c < (n_cols(d))) }
	-> { d2:DataSet | (n_cols(d2) == c) && (n_rows(d2) == n_rows(d)) }

sample :: { d:DataSet | true } 
	-> { n:Int | (n >= 0) && (n <= (n_rows(d))) } 
	-> { d2:DataSet | (n_rows(d2) == n) && (n_cols(d2) == n_cols(d)) }

train :: { d:DataSet | (n_rows(d) >= 10 * (n_cols(d))) } -> { m:Model | true }
\end{lstlisting}

When inspecting the liquid signatures above, we notice that only in |train| the number of rows directly interacts with the number of columns. For all other functions these two properties are orthogonal to each other. Current liquid type implementations are limited to this combined verification of these properties for all cases. However in \Cref{sssec:uc2_comparison} we will showcase the challenges of this approach and how our implementation can lift this limitation.

For our use-case we will look at three individual code snippets: One that only uses operations that manipulate the rows of a dataset, one that only manipulates columns and one that depends on both dimensions by using \texttt{train}. The three code snippets are show in \Cref{lst:uc2_code1,lst:uc2_code2,lst:uc2_code3}. A more in-depth explanation of the exmaples will follow in \Cref{sssec:uc2_comparison}.

\begin{minipage}{.45\textwidth}
\begin{lstlisting}[caption={Code example that only manipulates rows},label={lst:uc2_code1}]
let empty := create_dataset(10,0) in {
    let d := add_rows(empty, 50) in {
        sample(d, 10)
    }
}
\end{lstlisting}
\end{minipage}\hfill%
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[caption={Code example that only manipulates columns},label={lst:uc2_code2}]
let d := create_dataset(10,50) in {
    let d2 := add_cols(d, 100) in {
        reduce_cols(d2, 20)
    }
}
\end{lstlisting}	
\end{minipage}

\begin{center}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[caption={Caption that uses both rows and columns},label={lst:uc2_code3}]
let empty_d := create_dataset(10,0) in {
    let d := add_rows(empty_d, 50) in {
       let column := reduce_cols(d, 1) in {
           train(column)
       }

       let small_d := reduce_cols(d, 5) in {
           train(small_d)
       }
    }
}		
\end{lstlisting}
\end{minipage}
\end{center}
\subsubsection{Implementation Details}
\label{sssec:uc2_implementation}

Similar to the layers implemented for Use-Case 1, we implemented the verification layers based on the interpreter classes provided by \Lark. However, there is a slight difference: While the layers in our previous use-case had a static, predefined name, our liquid layer uses a more generic approach where the user can choose the layer name. This was an explicit design decision as it makes it easy to re-use the same liquid verification implementation to verify different liquid properties independently (See \Cref{sssec:uc2_comparison}).

As a basis for the liquid type checking we use our own fork of the \textsc{Aeon} language \footnote{See \url{https://github.com/LuAbelt/aeon-lt/tree/aeon-lt}}. Therefore, we use the same type definitions for liquid types as \textsc{Aeon} does. An example of this annotation style (excluding the layer identifier) can be seen in \Cref{lst:uc2_liq_sig}. It is possible to annotate both variable identifiers and function calls in our liquid layer. In a program, the verifier will perform a liquid type check for two specific scenarios:
\begin{itemize}
	\item When assigning an expression to a variable as part of a \texttt{let} statement
	\item When passing an expression as an argument to a function call
\end{itemize}

Consider the following example:

\begin{lstlisting}[caption={Simple example code of a liquid layer},label={lst:uc2_simple_example}]
var :: liquid :: { v:Int | v>0 }
fun :: liquid :: { arg:Int | arg>5 } -> {ret:Int | ret>=arg }

let var := fun(10) in {
	var
}
\end{lstlisting}

In this example two liquid type checks happen. First, it is checked, whether the integer literal \texttt{10} is a subtype of the defined type for the first argument of the function \texttt{fun}, which requires an argument greater than $5$. Internally, \textsc{Aeon} performs this typecheck by employing the constraint solver \textsc{Z3}, which effectively checks the following:

$$\forall v:Int | (v==10)\implies(v>5)$$

Since in liquid types, there can be cross-references to previously defined variables, to be able to verify this properly our layer also builds a \textit{typing context}(For brevity simply referred to as context from here on). This context contains the specific types for all previously defined and potentially referenced identifiers. This context will be extended by each \texttt{let} and each function call that is verified.

One thing to note about the context is, that when our liquid verification layer adds types to it, it will always add the most specific type that is known. For example, in the code snippet above, within the body of the \texttt{let} statement, we know that \texttt{var} will always be greater than $10$, even though purely by the liquid signature of \texttt{fun} we would only know that it always has to be greater than $5$. However, by adding the specific type of the argument passed to \texttt{fun} to the context we have a more precise information available.

The current context as well as resulting type of a node is also attached as additional meta-information to the AST. With this, our liquid layer implementation allows a novel technique that differentiates it from current implementations available: With this we can not only verify liquid properties independently from one another, but also allow later liquid layers to use type information provided by a previous liquid layer to be taken into account when type checking a joint layer. One usage of this will be shown in \Cref{sssec:uc2_comparison}. To allow this interaction with other liquid layers, the user simply provides a set of layer identifiers that will then be queried for additional type and context information.

\subsubsection{Comparison of monolithic to independent layers}
\label{sssec:uc2_comparison}

In the previously described examples, all the code presented was valid and consistent with the liquid signatures we described earlier. Thus, verifying them all within the same verification pass does not bear any issues. An examples of slightly adapted versions of the code are shown in \Cref{lst:uc2_code1_fail,lst:uc2_code2_fail,lst:uc2_code3_fail} that would lead to the verification errors shown in \Cref{lst:uc2_errors_monolithic}. For this simple code, even without profound domain knowledge it is relatively easy to spot that the errors are caused by the rows or columns respectively. The only error that might be slightly harder to interpret is the error caused by \texttt{train} since it is caused by an interaction of the two properties.

\begin{minipage}{.45\textwidth}
\begin{lstlisting}[caption={Adapted version of \Cref{lst:uc2_code1}},label={lst:uc2_code1_fail}]
let empty := create_dataset(10,0) in {
    let d := add_rows(empty, 50) in {
        sample(d, 100)
    }
}
\end{lstlisting}
\end{minipage}\hfill%
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[caption={Adapted version of \Cref{lst:uc2_code2}},label={lst:uc2_code2_fail}]
let d := create_dataset(10,50) in {
    reduce_cols(d, 20)
}
\end{lstlisting}	
\end{minipage}

\begin{center}
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[caption={Adapted version of \Cref{lst:uc2_code3}},label={lst:uc2_code3_fail}]
let empty_d := create_dataset(10,0) in {
    let d := add_rows(empty_d, 50) in {
       train(d)
    }
}
\end{lstlisting}
\end{minipage}
\end{center}

\begin{lstlisting}[caption={Error messages when using one monolithic liquid layer},label={lst:uc2_errors_monolithic},numbers=none]
-- Error in sample:
Layer 'liquid' failed with error: Error in function call to sample, argument 2:
{ v:Int | (v == 100) } is not a subtype of { n:Int | ((n >= 0) && (n <= n_rows(sample_d))) }
[...]

-- Error in reduce_cols:
Layer 'liquid' failed with error: Error in function call to reduce_cols, argument 2:
{ v:Int | (v == 20) } is not a subtype of { c:Int | ((c >= 0) && (c < n_cols(reduce_cols_d))) }
[...]

-- Error in train:
Layer 'liquid' failed with error: Error in function call to train, argument 1:
{ d2:DataSet | ((n_rows(d2) == (n_rows(add_rows_d) + add_rows_n)) && (n_cols(d2) == n_cols(add_rows_d))) } is not a subtype of { d:DataSet | (n_rows(d) >= (10 * n_cols(d))) }
[...]
\end{lstlisting}

However, there are also very basic examples, where such a distinction is not easily possible anymore. Consider the following example, where we have a dataset stored in a variable on which we want to both ensure a certain number of rows and a number of columns:

\begin{lstlisting}[caption={Small example of a dataset imposing restrictions on both rows and dimensions},label={lst:uc2_fail_monolithic}]
d :: liquid :: { d:DataSet | (n_rows(d)>100) && (n_cols(d)>10)}

let d := createDataset(10,1000) in {
	d
}
\end{lstlisting}

In this example, the programmer might have overlooked that the amount of columns needs to be greater than $10$. The resulting verification error is shown in \Cref{lst:uc2_error_mono}. For the developer, it is not directly evident that the error is caused by an issue with the number of rows. Only after careful inspection of the exact error and verification context, it is possible for the developer to properly identify this. 

\begin{lstlisting}[caption={Verification error produced by \Cref{lst:uc2_fail_monolithic}}]
Layer 'liquid' failed with error: Error during assigning identifier 'd' in let statement:
{ d:DataSet | ((n_cols(d) == create_dataset_c) && (n_rows(d) == create_dataset_r)) } is not a subtype of { d:DataSet | ((n_rows(d) > 100) && (n_cols(d) > 10)) }
In Context:
create_dataset_r : { v:Int | (v == 1000) }
create_dataset_c : { v:Int | (v == 10) }
(line 3)
\end{lstlisting}

Our implementation allows us to separate these individual checks into different verification passes. For the running example, we will consider three separate layers:

\begin{enumerate}
	\item \texttt{rows} -- This layer is only verifies all information that is only relevant to the number of rows of a dataset
	\item \texttt{cols} -- This layer only verifies information only relevant to the number of columns of a dataset
	\item \texttt{rowcols} -- This is a layer that verifies all \textit{interactions} between rows and columns of a dataset. It depends on the previous two layers and re-uses their contexts
\end{enumerate}

With this approach, each function and identifier will get three separate layer annotations, one for each respective layer. An example of how these annotations look for \texttt{create\_dataset} and \texttt{train} are shown in \Cref{lst:uc2_separate_liq_sigs}\footnote{For brevity, we omitted further examples for the other methods. However, they can be found in our GitHub repository}.

\begin{lstlisting}[numbers=none,caption={Liquid signatures for separate layers},label={lst:uc2_separate_liq_sigs},tabsize=4]
-- Only define requirements and effect on rows
create_dataset :: rows :: { c:Int | true } -> { r:Int | (r >= 0) } 
			-> { d:DataSet | (n_rows(d) == r) }

-- Only define requirements and effect on columns
create_dataset :: cols :: { c:Int | (c >=0) } -> { r:Int | true } 
			-> { d:DataSet | (n_cols(d) == c) }

-- No interaction between layers
create_dataset :: rowcols :: { c:Int | true } -> { r:Int | true } 
			-> { d:DataSet | true }

-- train does not have properties that only affect rows or column independently
train :: rows :: { d:DataSet | true } -> { m:Model | true }
train :: cols :: { d:DataSet | true } -> { m:Model | true }
-- Check the interaction
train :: rowcols :: { d:DataSet | (n_rows(d) >= 10*(n_cols(d))) } -> { m:Model | true }
\end{lstlisting}

Similarly, the example from \Cref{lst:uc2_fail_monolithic} slightly changes to the code shown in \Cref{lst:uc2_fail_separate}. With this new approach the verifier output changes as shown in \Cref{lst:uc2_error_separate}. It now provides with a much more accurate information from which we know, that all properties related to the number of rows could be verified but there was an error during verifying the \texttt{cols} layer. Subsequently, the \texttt{rowcols} layer is blocked for verification. Additionally we get a more concise error message for the verification error than we had when only using one monolithic layer.
\begin{lstlisting}[caption={Adapted version of \Cref{lst:uc2_fail_monolithic} that uses separate layers},label={lst:uc2_fail_separate}]
d :: rows :: { d:DataSet | (n_rows(d)>100)}
d :: cols :: { d:DataSet | (n_cols(d)>10)}
d :: liquid :: {d:DataSet | true }

let d := createDataset(10,1000) in {
	d
}
\end{lstlisting}
\begin{lstlisting}[caption={Verifier output produced by \Cref{lst:uc2_fail_separate}},label=lst:uc2_error_separate,numbers=none]
Not all layers could be verified.
The following layers were processed:
	rows: SUCCESS
	cols: FAILURE
	rowcols: BLOCKED


The following layers failed during typechecking:
	cols:
	 Layer 'cols' failed with error: 20:1: Error during assigning identifier 'd' in let statement:
{ d:DataSet | (n_cols(d) == create_dataset_c) } is not a subtype of { d:DataSet | (n_cols(d) > 10) }
In Context:
create_dataset_r : { v:Int | (v == 1000) }
create_dataset_c : { v:Int | (v == 10) }
\end{lstlisting}

Due to the spearation we now have much more detailled information on what exactly causes the liquid error. For a programmer this can make it much simpler to debug programs and fix liquid errors.

\subsubsection{Discussion and Limitations}
\label{sssec:uc2_discussion}

In this second use-case, we have successfully shown:
\begin{itemize}
	\item That our approach can be used to verify liquid types in general by providing a general liquid verification layer
	\item Furthermore we provided a small demonstration how the same implementation can be used to separate different concerns of liquid types into separate independent verification passes
	\item Lastly our implementation enables the re-use of type information provided by a liquid layer previously verified.
\end{itemize}

Especially for the separation of concerns we believe that this presents a novelty in the domain of liquid types as we are not aware of similar work in this field. However, we also have to discuss certain limitations that our implementation and approach may exhibit. We divide this limitations into conceptual and technical limitations.

\paragraph{Conceptual Limitations} -- While the separation of concerns for liquid properties presents a powerful mechanism, it also exposes a certain risk. When separating the concerns, the developer needs to have a clear understanding if and how properties of the affected functions and variables may affect each other or interact with one another. Meaning that the developer performing the separation into the different layers requires a profound domain knowledge of the system to be verified.

If this separation does not performed properly this could lead to undesired side effects. One example of of an unproper separation could happen when a developer decides to separate two properties in the assumption that they are independent if in reality they are not. In that case the two properties might lead to a valid program when verified independently drom one another, but when verified in conjunction one might realize that there are flaws in the system. Another example are properties that contradict each other.

This issue is related to correctly identifying the dependencies and interactions between properties. For a sufficient large software systems it might not be trivial to identify the dependencies and interactions between different parts of the system. Similar findings have been made in the domain of Software-Product Line Engineering when identifying interactions between features\cite{apel2013}.

\paragraph{Technical Limitations} Our prototype exhibits some technical limitations that might reduce the applicability of our implementation on bigger systems. First and foremost, since we limit ourselves to the small example language that we designed ourselves, using it on real-world examples would require and considerable amount of work to develop a proper wrapper with our language and the built-in python integration.

Additionally, our prototype only allows to bind variables for a specific scope via the \texttt{let} statement. Reassigning an existing variable to a new value is not possible. Additionally, all the identifiers and functions need to be fully annotated even if the specific layer does not require or add any new information about them (As seen in for example \texttt{train} for the layers \texttt{rows} and \texttt{cols} in \Cref{lst:uc2_separate_liq_sigs}). However, we believe that this design decision is a more safer one than allowing unannotated identifiers that are simply not verified, as it adds an additional level of explicitness to the verification process. However, with many layers this leads to a considerable amount of additional boilerplate code that might be required.

Lastly, our implementation currently also might suffer from a general scalability issue, when using the feature to consider additional contexts during verification. During verification the current context is merged with all the dependent contexts. This merged context is then also used for the further verification steps. However the next time this new context is merged again with the dependent contexts, there is no mechanism in place that checks whether the variables from the additional contexts have already been merged. This leads to multiple independent copies of the same variables (With varying names) existing in the context.

This shortcoming of our implementation however could be fixed with little implementation effort. One simply needs to keep track which variables have already been added to the context previously and what they might have been renamed to. When then merging the contexts a second time, already existing variables would simply be skipped. However, due to limited time this feature is not yet present in our prototype.
