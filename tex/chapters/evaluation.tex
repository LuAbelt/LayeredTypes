\section{Evaluation}
\label{sec:evaluation}

In this section we will critically to evaluate our implemented approach and in which capacity we where able to answer our research questions. In RQ1, we aksed whether it is possible for us to define a layered type system that can be used to verify different properties independently from one another.

We believe that our approach has successfully shown that you can build an implementation that flexibly allows to verify independent properties of different type systems independently from each other. In particular, use case 1 has shown an applied example of this layered type system. However, in this work we do not present a formalized description of such a layered type system. This might be particulary relevant when building and formalizing different type layers that depend and interact with each other.

Additionally, the system we built is rather limited; While our language supports all basic constructs of a programming language which allows it to also build complex functionality, we are limited to this simple syntax. In order to apply our layered verification approach to already exisiting software a non-insignificant integration effort might be required. Therefore our implementation should rather be viewed as a stand-alone prototype that merely evaluates the theoretical possibilities and potential limits of such a system.

For RQ2, which focusses on how and if this approach can be used to improve current liquid type implementations, we have achieved mixed results: One the one hand, we have successfully shown in use-case 2 that we can built an implementation that can achieve this on a small scale. However, the exact implementation of this has proven rather complicated. Due to limited time we were not able to evaluate the implementation on a more complex example which might potentially unveil further implementation issues and bugs.

Additionally, our implementation faces similar scalability challenges as the ones we also face for RQ1, when trying to take this approach to real-world software. Lastly, our research question specifically asked whether our approach improves challenges that are present in current Liquid Type implementations. We believe that our approach can improve a few challenges from liquid types, mainly identifying the source of a liquid type errors by cleanly dividing the responsibilities into separate verification passes. However we also note that this division itself might be non-trivial and required advanced domain knowledge.

Lastly, our layered approach does not improve the interpretability of the liquid error messages itself. When considering the example of \Cref{lst:uc2_code3_fail}, when verified with separated layers, the error message still gets very verbose and hard to interpret as shown in \Cref{lst:uc2_code3_error}. One reason for this is certainly the issue already mentioned in \Cref{sssec:uc2_discussion}, that our context currently grows faster than it needs. We therefore think that further work needs to be done to improve liquid error messages itself.

\begin{lstlisting}[caption={Error message for \Cref{lst:uc2_code3_fail}},label={lst:uc2_code3_error}]
Layer 'rowcols' failed with error: 24:5: Error in function call to train, argument 1:
{ d:DataSet | ((((true && (n_cols(d) == create_dataset_c)) && (n_rows(d) == create_dataset_r)) && (n_cols(d) == create_dataset_c)) && (n_rows(d) == create_dataset_r)) } is not a subtype of { d:DataSet | (n_rows(d) >= (10 * n_cols(d))) }
In Context:
[... 12 lines of context omitted ...]
\end{lstlisting}
